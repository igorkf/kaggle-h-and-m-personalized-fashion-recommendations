{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def apk(actual, predicted, k=12):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=12):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted\n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv('LOCAL'):\n",
    "    print('local')\n",
    "    INPUT_DIR = Path('./input/transformed')\n",
    "    OUTPUT_DIR = Path('./output')\n",
    "else:\n",
    "    print('kaggle')\n",
    "    INPUT_DIR = Path('../input/transformed')\n",
    "    OUTPUT_DIR = Path('/kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_pickle(INPUT_DIR / 'transactions_train.pkl')[['user', 'item', 't_dat']]\n",
    "valid_start_date = datetime.date(2020, 9, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_stats(train, valid):\n",
    "    train_users = set(train.user)\n",
    "    train_items = set(train.item)\n",
    "    valid_users = set(valid.user)\n",
    "    valid_items = set(valid.item)\n",
    "    print(f\"train transaction: {len(train)}, train user: {len(train_users)}, train item: {len(train_items)}\")\n",
    "    print(f\"valid transaction: {len(valid)}, valid user: {len(valid_users)}, valid item: {len(valid_items)}\")\n",
    "    print(f\"valid user coverage: {len(train_users & valid_users) / len(valid_users)}\")\n",
    "    print(f\"valid item coverage: {len(train_items & valid_items) / len(valid_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_days = 60\n",
    "recent_item_days = 7\n",
    "recent_user_days = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train vaild split\")\n",
    "train_start_date = valid_start_date - datetime.timedelta(days=train_days)\n",
    "train = transactions.query(\"@train_start_date <= t_dat < @valid_start_date\").reset_index(drop=True)\n",
    "valid = transactions.query(\"@valid_start_date <= t_dat\").reset_index(drop=True)\n",
    "del transactions\n",
    "train_valid_stats(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"filter recent items\")\n",
    "train_item_start_date = valid_start_date - datetime.timedelta(days=recent_item_days)\n",
    "recent_items = set(train.query(\"@train_item_start_date <= t_dat < @valid_start_date\")['item'])\n",
    "train = train.query(\"item in @recent_items\").reset_index(drop=True)\n",
    "train_valid_stats(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"filter each user recent transactions (train)\")\n",
    "train['last_t_dat'] = train.groupby('user').t_dat.transform(max)\n",
    "train['diff_t_dat'] = (train.last_t_dat - train.t_dat).dt.days\n",
    "train = train.query(\"diff_t_dat < @recent_user_days\").reset_index(drop=True)\n",
    "train_valid_stats(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"drop duplicates (train)\")\n",
    "train = train[['user', 'item']]\n",
    "valid = valid[['user', 'item']]\n",
    "train = train.drop_duplicates(ignore_index=True)\n",
    "train_valid_stats(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"drop users and items which apper only once (train)\")\n",
    "for _ in range(3):\n",
    "    users = train.groupby('user').size().reset_index(name='sz').query(\"sz > 1\").user\n",
    "    train = train.query(\"user in @users\")\n",
    "    print(train.shape, len(train.user.unique()), len(train.item.unique()))\n",
    "\n",
    "    items = train.groupby('item').size().reset_index(name='sz').query(\"sz > 1\").item\n",
    "    train = train.query(\"item in @items\")\n",
    "    print(train.shape, len(train.user.unique()), len(train.item.unique()))\n",
    "\n",
    "train_valid_stats(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGCNが学習できるような形式にする\n",
    "# - testのみに含まれるユーザーがあってはいけない\n",
    "# - カラム名をあわせる\n",
    "# - ratingカラムを追加\n",
    "users = sorted(set(train.user))\n",
    "valid = valid.query(\"user in @users\")\n",
    "\n",
    "train = train.rename(columns={'user': 'userID', 'item': 'itemID'})\n",
    "valid = valid.rename(columns={'user': 'userID', 'item': 'itemID'})\n",
    "train['rating'] = 1\n",
    "valid['rating'] = 1\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImplicitCF(train=train, test=valid, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = prepare_hparams(\n",
    "    model_type='lightgcn',\n",
    "    embed_size=128,\n",
    "    n_layers=3,\n",
    "    batch_size=8192,\n",
    "    decay=0.0001,\n",
    "    epochs=1000,\n",
    "    learning_rate=0.001,\n",
    "    eval_epoch=10,\n",
    "    top_k=12,\n",
    "    save_model=True,\n",
    "    save_epoch=100,\n",
    "    metrics=['recall', 'ndcg', 'precision', 'map'],\n",
    "    MODEL_DIR=str(OUTPUT_DIR),\n",
    ")\n",
    "with Timer() as prepare_time:\n",
    "    model = LightGCN(hparams, data, seed=42)\n",
    "del data\n",
    "print(f\"{prepare_time.interval} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "with Timer() as train_time:\n",
    "    model.fit()\n",
    "print(f\"{train_time.interval} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid oom\n",
    "tmp = valid[['userID']].drop_duplicates()\n",
    "step = len(tmp) // 10\n",
    "res = []\n",
    "for i in range(0, len(tmp), step):\n",
    "    res.append(model.recommend_k_items(tmp.iloc[i:i+step], top_k=12, remove_seen=False))\n",
    "pred = pd.concat(res).reset_index(drop=True)\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.rename(columns={'userID': 'user', 'itemID': 'item_pred'})\n",
    "pred = pred.groupby('user')['item_pred'].apply(list).reset_index()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_pickle(INPUT_DIR / 'transactions_train.pkl')[['user', 'item', 't_dat']].query(\"t_dat >= @valid_start_date\")[['user', 'item']].rename(columns={'item': 'item_valid'}).reset_index(drop=True)\n",
    "valid = valid.groupby('user')['item_valid'].apply(list).reset_index()\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = valid.merge(pred, on='user')\n",
    "mpk = mapk(merged['item_valid'], merged['item_pred'])\n",
    "users_valid = set(valid['user'])\n",
    "users_merged = set(merged['user'])\n",
    "user_coverage = len(users_valid & users_merged) / len(users_valid)\n",
    "print(f\"mapk: {mpk}, user coverage: {user_coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv(OUTPUT_DIR / 'pred.csv', index=False)\n",
    "model.infer_embedding(OUTPUT_DIR / 'user_emb.csv', OUTPUT_DIR / 'item_emb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fdfdbd45d085a0ba7113cd82f547db5c004cd8ea43fffd106ba9e69f1df9763"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('rec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
