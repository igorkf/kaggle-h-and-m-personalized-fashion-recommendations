{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM (fresh records)\n",
    "* trainは各ユーザーの最新購入から3週間以内のデータのみ使う\n",
    "* 基本的には直近3週間を使いたい & 古いユーザーに関する情報が完全になくなるのを防ぐ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from lightfm import LightFM\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "import schema\n",
    "from metric import mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('input/transformed/transactions_train.csv', parse_dates=['t_dat'], usecols=list(schema.TRANSACTIONS.keys())+['t_dat'], dtype=schema.TRANSACTIONS)\n",
    "n_user = transactions.customer_id_idx.max() + 1\n",
    "n_item = transactions.article_id_idx.max() + 1\n",
    "TOPK = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 100/100 [01:22<00:00,  1.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.020466072378020644"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_days = 21\n",
    "no_components = 256\n",
    "learning_schedule = 'adadelta'\n",
    "loss = 'bpr'\n",
    "learning_rate = 0.005\n",
    "item_alpha = 1e-8\n",
    "user_alpha = 1e-8\n",
    "max_sampled = 20\n",
    "epochs = 100\n",
    "\n",
    "lightfm_params = {\n",
    "    'no_components': no_components,\n",
    "    'learning_schedule': learning_schedule,\n",
    "    'loss': loss,\n",
    "    'learning_rate': learning_rate,\n",
    "    'item_alpha': item_alpha,\n",
    "    'user_alpha': user_alpha,\n",
    "    'max_sampled': max_sampled,\n",
    "}\n",
    "\n",
    "valid_start_date = datetime.date(2020, 9, 16)\n",
    "valid_end_date = datetime.date(2020, 9, 22)\n",
    "train_start_date = valid_start_date - datetime.timedelta(days=train_days)\n",
    "train_end_date = valid_start_date - datetime.timedelta(days=1)\n",
    "\n",
    "transactions_train = transactions.query(\"@train_start_date <= t_dat <= @train_end_date\").reset_index(drop=True)\n",
    "transactions_valid = transactions.query(\"@valid_start_date <= t_dat <= @valid_end_date\")\n",
    "\n",
    "val = transactions_valid.groupby('customer_id_idx')['article_id_idx'].apply(list).reset_index()\n",
    "\n",
    "train = lil_matrix((n_user, n_item))\n",
    "train[transactions_train.customer_id_idx, transactions_train.article_id_idx] = 1\n",
    "\n",
    "model = LightFM(**lightfm_params)\n",
    "model.fit(train, epochs=epochs, num_threads=psutil.cpu_count(logical=False), verbose=True)\n",
    "\n",
    "index = faiss.index_factory(no_components, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, index)\n",
    "index.add(model.item_embeddings)\n",
    "_, idxs = index.search(model.user_embeddings, TOPK)\n",
    "\n",
    "mapk(val.article_id_idx, idxs[val.customer_id_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 31548013\n",
      "after 6028836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 100/100 [07:16<00:00,  4.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.019526944110053766"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_days = 21\n",
    "no_components = 256\n",
    "learning_schedule = 'adadelta'\n",
    "loss = 'bpr'\n",
    "learning_rate = 0.005\n",
    "item_alpha = 1e-8\n",
    "user_alpha = 1e-8\n",
    "max_sampled = 20\n",
    "epochs = 100\n",
    "\n",
    "lightfm_params = {\n",
    "    'no_components': no_components,\n",
    "    'learning_schedule': learning_schedule,\n",
    "    'loss': loss,\n",
    "    'learning_rate': learning_rate,\n",
    "    'item_alpha': item_alpha,\n",
    "    'user_alpha': user_alpha,\n",
    "    'max_sampled': max_sampled,\n",
    "}\n",
    "\n",
    "valid_start_date = datetime.date(2020, 9, 16)\n",
    "valid_end_date = datetime.date(2020, 9, 22)\n",
    "\n",
    "transactions_train = transactions.query(\"t_dat < @valid_start_date\").reset_index(drop=True)\n",
    "transactions_valid = transactions.query(\"@valid_start_date <= t_dat <= @valid_end_date\")\n",
    "\n",
    "transactions_train['last_t_dat'] = transactions_train.groupby('customer_id_idx').t_dat.transform(max)\n",
    "transactions_train['diff_t_dat'] = (transactions_train.last_t_dat - transactions_train.t_dat).dt.days\n",
    "print('before', len(transactions_train))\n",
    "transactions_train = transactions_train.query(\"diff_t_dat <= @train_days\").reset_index(drop=True)\n",
    "print('after', len(transactions_train))\n",
    "\n",
    "val = transactions_valid.groupby('customer_id_idx')['article_id_idx'].apply(list).reset_index()\n",
    "\n",
    "train = lil_matrix((n_user, n_item))\n",
    "train[transactions_train.customer_id_idx, transactions_train.article_id_idx] = 1\n",
    "\n",
    "model = LightFM(**lightfm_params)\n",
    "model.fit(train, epochs=epochs, num_threads=psutil.cpu_count(logical=False), verbose=True)\n",
    "\n",
    "index = faiss.index_factory(no_components, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, index)\n",
    "index.add(model.item_embeddings)\n",
    "_, idxs = index.search(model.user_embeddings, TOPK)\n",
    "\n",
    "mapk(val.article_id_idx, idxs[val.customer_id_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customerが増えたことで、エポック数が足りなくなったのでは？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 31548013\n",
      "after 6028836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1000/1000 [1:11:45<00:00,  4.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.019937798355488014"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_days = 21\n",
    "no_components = 256\n",
    "learning_schedule = 'adadelta'\n",
    "loss = 'bpr'\n",
    "learning_rate = 0.005\n",
    "item_alpha = 1e-8\n",
    "user_alpha = 1e-8\n",
    "max_sampled = 20\n",
    "epochs = 1000\n",
    "\n",
    "lightfm_params = {\n",
    "    'no_components': no_components,\n",
    "    'learning_schedule': learning_schedule,\n",
    "    'loss': loss,\n",
    "    'learning_rate': learning_rate,\n",
    "    'item_alpha': item_alpha,\n",
    "    'user_alpha': user_alpha,\n",
    "    'max_sampled': max_sampled,\n",
    "}\n",
    "\n",
    "valid_start_date = datetime.date(2020, 9, 16)\n",
    "valid_end_date = datetime.date(2020, 9, 22)\n",
    "\n",
    "transactions_train = transactions.query(\"t_dat < @valid_start_date\").reset_index(drop=True)\n",
    "transactions_valid = transactions.query(\"@valid_start_date <= t_dat <= @valid_end_date\")\n",
    "\n",
    "transactions_train['last_t_dat'] = transactions_train.groupby('customer_id_idx').t_dat.transform(max)\n",
    "transactions_train['diff_t_dat'] = (transactions_train.last_t_dat - transactions_train.t_dat).dt.days\n",
    "print('before', len(transactions_train))\n",
    "transactions_train = transactions_train.query(\"diff_t_dat <= @train_days\").reset_index(drop=True)\n",
    "print('after', len(transactions_train))\n",
    "\n",
    "val = transactions_valid.groupby('customer_id_idx')['article_id_idx'].apply(list).reset_index()\n",
    "\n",
    "train = lil_matrix((n_user, n_item))\n",
    "train[transactions_train.customer_id_idx, transactions_train.article_id_idx] = 1\n",
    "\n",
    "model = LightFM(**lightfm_params)\n",
    "model.fit(train, epochs=epochs, num_threads=psutil.cpu_count(logical=False), verbose=True)\n",
    "\n",
    "index = faiss.index_factory(no_components, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, index)\n",
    "index.add(model.item_embeddings)\n",
    "_, idxs = index.search(model.user_embeddings, TOPK)\n",
    "\n",
    "mapk(val.article_id_idx, idxs[val.customer_id_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そんなことはなかった:astonished:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c89b5301ada1d96cd3523f144e4a3cd3ad36f6698a61e6b8277fb627756a86c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('3.9.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
