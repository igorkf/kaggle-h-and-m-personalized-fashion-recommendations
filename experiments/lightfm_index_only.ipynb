{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM (index only)\n",
    "* インデックスのみを使う\n",
    "* そのまま各ユーザーに対して内積が近いアイテム上位12件をfaissで求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from lightfm import LightFM\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "import schema\n",
    "from metric import mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('input/transformed/transactions_train.csv', parse_dates=['t_dat'], usecols=list(schema.TRANSACTIONS.keys())+['t_dat'], dtype=schema.TRANSACTIONS)\n",
    "n_user = transactions.customer_id_idx.max() + 1\n",
    "n_item = transactions.article_id_idx.max() + 1\n",
    "TOPK = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    train_days = trial.suggest_int('train_days', 7, 70, 7)\n",
    "    no_components = trial.suggest_int('no_components', 16, 128, 16)\n",
    "    learning_schedule = trial.suggest_categorical('learning_schedule', ['adagrad', 'adadelta'])\n",
    "    loss = trial.suggest_categorical('loss', ['bpr', 'warp'])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    item_alpha = trial.suggest_loguniform('item_alpha', 1e-12, 1e-2)\n",
    "    user_alpha = trial.suggest_loguniform('user_alpha', 1e-12, 1e-2)\n",
    "    max_sampled = trial.suggest_int('max_sampled', 10, 20, 10)\n",
    "    epochs = 100\n",
    "\n",
    "    lightfm_params = {\n",
    "        'no_components': no_components,\n",
    "        'learning_schedule': learning_schedule,\n",
    "        'loss': loss,\n",
    "        'learning_rate': learning_rate,\n",
    "        'item_alpha': item_alpha,\n",
    "        'user_alpha': user_alpha,\n",
    "        'max_sampled': max_sampled,\n",
    "    }\n",
    "\n",
    "    valid_start_date = datetime.date(2020, 9, 16)\n",
    "    valid_end_date = datetime.date(2020, 9, 22)\n",
    "    train_end_date = valid_start_date - datetime.timedelta(days=1)\n",
    "    train_start_date = valid_start_date - datetime.timedelta(days=train_days)\n",
    "\n",
    "    transactions_train = transactions.query(\"@train_start_date <= t_dat <= @train_end_date\")\n",
    "    transactions_valid = transactions.query(\"@valid_start_date <= t_dat <= @valid_end_date\")\n",
    "\n",
    "    val = transactions_valid.groupby('customer_id_idx')['article_id_idx'].apply(list).reset_index()\n",
    "\n",
    "    train = lil_matrix((n_user, n_item))\n",
    "    train[transactions_train.customer_id_idx, transactions_train.article_id_idx] = 1\n",
    "\n",
    "    model = LightFM(**lightfm_params)\n",
    "    model.fit(train, epochs=epochs, num_threads=psutil.cpu_count(logical=False), verbose=True)\n",
    "\n",
    "    index = faiss.index_factory(no_components, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "    index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, index)\n",
    "    index.add(model.item_embeddings)\n",
    "    _, idxs = index.search(model.user_embeddings, TOPK)\n",
    "\n",
    "    return mapk(val.article_id_idx, idxs[val.customer_id_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-04 12:57:20,535]\u001b[0m A new study created in memory with name: no-name-aa474d6b-d295-48a0-9793-07af0a1c221e\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:13<00:00,  1.35it/s]\n",
      "\u001b[32m[I 2022-03-04 12:58:46,730]\u001b[0m Trial 0 finished with value: 3.504378286936561e-05 and parameters: {'train_days': 49, 'no_components': 96, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 1.1073228281982184e-05, 'item_alpha': 1.2101237633851377e-10, 'max_sampled': 20}. Best is trial 0 with value: 3.504378286936561e-05.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [02:11<00:00,  1.31s/it]\n",
      "\u001b[32m[I 2022-03-04 13:01:08,333]\u001b[0m Trial 1 finished with value: 0.01370055437915843 and parameters: {'train_days': 49, 'no_components': 64, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0033631506159568355, 'item_alpha': 3.253240421379212e-09, 'max_sampled': 20}. Best is trial 1 with value: 0.01370055437915843.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:56<00:00,  1.78it/s]\n",
      "\u001b[32m[I 2022-03-04 13:02:13,321]\u001b[0m Trial 2 finished with value: 2.3834892010845856e-05 and parameters: {'train_days': 56, 'no_components': 16, 'learning_schedule': 'adagrad', 'loss': 'warp', 'learning_rate': 4.576352504964384e-05, 'item_alpha': 1.3285928847155422e-05, 'max_sampled': 10}. Best is trial 1 with value: 0.01370055437915843.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:43<00:00,  1.03s/it]\n",
      "\u001b[32m[I 2022-03-04 13:04:09,184]\u001b[0m Trial 3 finished with value: 0.018800450082024123 and parameters: {'train_days': 28, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.00100034976741604, 'item_alpha': 1.628248206793105e-05, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:18<00:00,  1.27it/s]\n",
      "\u001b[32m[I 2022-03-04 13:05:39,009]\u001b[0m Trial 4 finished with value: 0.00925744536736042 and parameters: {'train_days': 42, 'no_components': 96, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 0.0044441791658520885, 'item_alpha': 4.113665603209978e-09, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:52<00:00,  1.13s/it]\n",
      "\u001b[32m[I 2022-03-04 13:07:44,308]\u001b[0m Trial 5 finished with value: 3.82753915457151e-05 and parameters: {'train_days': 56, 'no_components': 112, 'learning_schedule': 'adagrad', 'loss': 'warp', 'learning_rate': 1.2087836311573116e-05, 'item_alpha': 5.852985965964573e-09, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:51<00:00,  1.12s/it]\n",
      "\u001b[32m[I 2022-03-04 13:09:46,664]\u001b[0m Trial 6 finished with value: 0.012959093890639345 and parameters: {'train_days': 70, 'no_components': 64, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.005777074032375277, 'item_alpha': 1.081462505697355e-11, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:34<00:00,  2.93it/s]\n",
      "\u001b[32m[I 2022-03-04 13:10:30,015]\u001b[0m Trial 7 finished with value: 0.0032200963726065164 and parameters: {'train_days': 21, 'no_components': 48, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.004276128302039446, 'item_alpha': 0.00010002879170299122, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:14<00:00,  6.68it/s]\n",
      "\u001b[32m[I 2022-03-04 13:10:52,931]\u001b[0m Trial 8 finished with value: 2.442718152675741e-05 and parameters: {'train_days': 14, 'no_components': 16, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 1.2289744006082842e-05, 'item_alpha': 1.883188419323383e-08, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:52<00:00,  1.12s/it]\n",
      "\u001b[32m[I 2022-03-04 13:12:56,141]\u001b[0m Trial 9 finished with value: 1.8634201560677265e-05 and parameters: {'train_days': 63, 'no_components': 80, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 0.00018610276885327678, 'item_alpha': 8.310543422547165e-12, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:13<00:00,  1.36it/s]\n",
      "\u001b[32m[I 2022-03-04 13:14:21,131]\u001b[0m Trial 10 finished with value: 0.0002593340251166704 and parameters: {'train_days': 28, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0007711692462629747, 'item_alpha': 0.002908225196130583, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:39<00:00,  1.01it/s]\n",
      "\u001b[32m[I 2022-03-04 13:16:09,417]\u001b[0m Trial 11 finished with value: 0.013869390816229106 and parameters: {'train_days': 35, 'no_components': 48, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0010349397565231492, 'item_alpha': 1.1891666894583778e-06, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:19<00:00,  1.26it/s]\n",
      "\u001b[32m[I 2022-03-04 13:17:37,180]\u001b[0m Trial 12 finished with value: 0.014737808200493356 and parameters: {'train_days': 28, 'no_components': 48, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0008328966687371053, 'item_alpha': 3.518149443499574e-06, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:40<00:00,  2.48it/s]\n",
      "\u001b[32m[I 2022-03-04 13:18:29,348]\u001b[0m Trial 13 finished with value: 0.01470187760778997 and parameters: {'train_days': 7, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.00023148732251060029, 'item_alpha': 5.906337484753074e-07, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n",
      "\u001b[32m[I 2022-03-04 13:19:31,386]\u001b[0m Trial 14 finished with value: 0.0005734346770402233 and parameters: {'train_days': 28, 'no_components': 32, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0008809546808427851, 'item_alpha': 0.000370645181650745, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:12<00:00,  1.38it/s]\n",
      "\u001b[32m[I 2022-03-04 13:20:53,746]\u001b[0m Trial 15 finished with value: 0.017463335244645023 and parameters: {'train_days': 21, 'no_components': 80, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.00144580409710534, 'item_alpha': 8.685272070229075e-06, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:36<00:00,  2.77it/s]\n",
      "\u001b[32m[I 2022-03-04 13:21:40,885]\u001b[0m Trial 16 finished with value: 0.014738251000360433 and parameters: {'train_days': 7, 'no_components': 96, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0017620300517891057, 'item_alpha': 4.1989375433398393e-05, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:51<00:00,  1.93it/s]\n",
      "\u001b[32m[I 2022-03-04 13:22:44,517]\u001b[0m Trial 17 finished with value: 0.016581420807160827 and parameters: {'train_days': 21, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 7.72772366128138e-05, 'item_alpha': 8.54837562464648e-08, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:27<00:00,  1.15it/s]\n",
      "\u001b[32m[I 2022-03-04 13:24:21,968]\u001b[0m Trial 18 finished with value: 0.004058737848670331 and parameters: {'train_days': 35, 'no_components': 80, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.008558467577067689, 'item_alpha': 0.0031553838348826095, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:49<00:00,  2.00it/s]\n",
      "\u001b[32m[I 2022-03-04 13:25:23,953]\u001b[0m Trial 19 finished with value: 0.0015334774878023156 and parameters: {'train_days': 14, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.00038366968667590147, 'item_alpha': 0.00021387665993933272, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:56<00:00,  1.78it/s]\n",
      "\u001b[32m[I 2022-03-04 13:26:31,774]\u001b[0m Trial 20 finished with value: 0.01681512676630988 and parameters: {'train_days': 21, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.001974156858944429, 'item_alpha': 2.1572259528905366e-07, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:56<00:00,  1.77it/s]\n",
      "\u001b[32m[I 2022-03-04 13:27:39,922]\u001b[0m Trial 21 finished with value: 0.016854169563088547 and parameters: {'train_days': 21, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0019308296951495475, 'item_alpha': 1.725917395860677e-07, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:51<00:00,  1.93it/s]\n",
      "\u001b[32m[I 2022-03-04 13:28:43,370]\u001b[0m Trial 22 finished with value: 0.017456157826591105 and parameters: {'train_days': 21, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0018592166467478292, 'item_alpha': 1.0592523682209713e-05, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:40<00:00,  2.46it/s]\n",
      "\u001b[32m[I 2022-03-04 13:29:34,866]\u001b[0m Trial 23 finished with value: 0.016326426665507543 and parameters: {'train_days': 14, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0004298319493604593, 'item_alpha': 6.499840393607331e-06, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:10<00:00,  1.43it/s]\n",
      "\u001b[32m[I 2022-03-04 13:30:55,598]\u001b[0m Trial 24 finished with value: 0.016388092661021703 and parameters: {'train_days': 35, 'no_components': 96, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0021584746596816874, 'item_alpha': 2.5477999814364634e-05, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:11<00:00,  1.39it/s]\n",
      "\u001b[32m[I 2022-03-04 13:32:17,535]\u001b[0m Trial 25 finished with value: 0.0002502945050673509 and parameters: {'train_days': 28, 'no_components': 80, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0005012811025932838, 'item_alpha': 0.0004040902019337838, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:27<00:00,  1.15it/s]\n",
      "\u001b[32m[I 2022-03-04 13:33:56,458]\u001b[0m Trial 26 finished with value: 0.01601514113153854 and parameters: {'train_days': 42, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.00014385718195284345, 'item_alpha': 2.1405146002875627e-06, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:55<00:00,  1.80it/s]\n",
      "\u001b[32m[I 2022-03-04 13:35:03,611]\u001b[0m Trial 27 finished with value: 0.0009852279588786499 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0013714204025004001, 'item_alpha': 0.0015849934898859858, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:26<00:00,  3.83it/s]\n",
      "\u001b[32m[I 2022-03-04 13:35:40,580]\u001b[0m Trial 28 finished with value: 0.013940485013704774 and parameters: {'train_days': 7, 'no_components': 96, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0028999163093580667, 'item_alpha': 3.215072859152674e-05, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:44<00:00,  2.26it/s]\n",
      "\u001b[32m[I 2022-03-04 13:36:34,592]\u001b[0m Trial 29 finished with value: 0.013089013026875288 and parameters: {'train_days': 28, 'no_components': 64, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 0.008734391044271808, 'item_alpha': 2.3801274946761585e-08, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [11:47<00:00,  7.07s/it]\n",
      "\u001b[32m[I 2022-03-04 13:48:32,558]\u001b[0m Trial 30 finished with value: 0.0 and parameters: {'train_days': 21, 'no_components': 96, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0005919058013978617, 'item_alpha': 0.009244559939411064, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:56<00:00,  1.78it/s]\n",
      "\u001b[32m[I 2022-03-04 13:49:40,305]\u001b[0m Trial 31 finished with value: 0.016606711767459606 and parameters: {'train_days': 21, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.001250176021509924, 'item_alpha': 6.004155798084503e-10, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n",
      "\u001b[32m[I 2022-03-04 13:50:37,509]\u001b[0m Trial 32 finished with value: 0.01609124079713737 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.002695883250486709, 'item_alpha': 3.385415322819537e-07, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:51<00:00,  1.94it/s]\n",
      "\u001b[32m[I 2022-03-04 13:51:40,782]\u001b[0m Trial 33 finished with value: 0.016930767619252798 and parameters: {'train_days': 21, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0014927310364702255, 'item_alpha': 7.063470096647225e-06, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:12<00:00,  1.37it/s]\n",
      "\u001b[32m[I 2022-03-04 13:53:05,529]\u001b[0m Trial 34 finished with value: 0.01649259923195841 and parameters: {'train_days': 35, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0014351743537534285, 'item_alpha': 6.995367510226188e-06, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:27<00:00,  1.15it/s]\n",
      "\u001b[32m[I 2022-03-04 13:54:44,795]\u001b[0m Trial 35 finished with value: 0.0036762461239957874 and parameters: {'train_days': 42, 'no_components': 112, 'learning_schedule': 'adagrad', 'loss': 'warp', 'learning_rate': 0.004075423238077416, 'item_alpha': 8.903392147138989e-05, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:55<00:00,  1.82it/s]\n",
      "\u001b[32m[I 2022-03-04 13:55:50,097]\u001b[0m Trial 36 finished with value: 0.016388946489861493 and parameters: {'train_days': 28, 'no_components': 80, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.0007496224702807248, 'item_alpha': 1.1146160003122398e-05, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:35<00:00,  2.79it/s]\n",
      "\u001b[32m[I 2022-03-04 13:56:36,945]\u001b[0m Trial 37 finished with value: 0.011525934177383833 and parameters: {'train_days': 21, 'no_components': 96, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 0.006204039152344165, 'item_alpha': 1.4724060367648313e-06, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:35<00:00,  1.05it/s]\n",
      "\u001b[32m[I 2022-03-04 13:58:22,949]\u001b[0m Trial 38 finished with value: 0.014420192786503878 and parameters: {'train_days': 49, 'no_components': 96, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.00029594072196154346, 'item_alpha': 1.2886232496216562e-12, 'max_sampled': 10}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:38<00:00,  2.61it/s]\n",
      "\u001b[32m[I 2022-03-04 13:59:12,777]\u001b[0m Trial 39 finished with value: 0.018577159978848016 and parameters: {'train_days': 14, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.00288253298353013, 'item_alpha': 4.525118998544838e-08, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:31<00:00,  3.13it/s]\n",
      "\u001b[32m[I 2022-03-04 13:59:54,865]\u001b[0m Trial 40 finished with value: 0.009256347273662906 and parameters: {'train_days': 14, 'no_components': 80, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 0.0035147289118637897, 'item_alpha': 1.572678386909373e-09, 'max_sampled': 20}. Best is trial 3 with value: 0.018800450082024123.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:40<00:00,  2.47it/s]\n",
      "\u001b[32m[I 2022-03-04 14:00:47,111]\u001b[0m Trial 41 finished with value: 0.018818549579307776 and parameters: {'train_days': 14, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.002415720220540051, 'item_alpha': 3.0541452344252375e-08, 'max_sampled': 20}. Best is trial 41 with value: 0.018818549579307776.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:27<00:00,  3.66it/s]\n",
      "\u001b[32m[I 2022-03-04 14:01:25,624]\u001b[0m Trial 42 finished with value: 0.016383202707386225 and parameters: {'train_days': 7, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0062882276028330035, 'item_alpha': 4.305723892309654e-09, 'max_sampled': 20}. Best is trial 41 with value: 0.018818549579307776.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:41<00:00,  2.39it/s]\n",
      "\u001b[32m[I 2022-03-04 14:02:19,349]\u001b[0m Trial 43 finished with value: 0.018963134725595587 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0023317549633062205, 'item_alpha': 2.314335248773534e-08, 'max_sampled': 20}. Best is trial 43 with value: 0.018963134725595587.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:42<00:00,  2.34it/s]\n",
      "\u001b[32m[I 2022-03-04 14:03:14,263]\u001b[0m Trial 44 finished with value: 0.01908571926534241 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0026681182132012693, 'item_alpha': 2.3337339755667528e-08, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:29<00:00,  3.39it/s]\n",
      "\u001b[32m[I 2022-03-04 14:03:55,959]\u001b[0m Trial 45 finished with value: 0.016450088931396198 and parameters: {'train_days': 7, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0049489335642786654, 'item_alpha': 1.1150990127788294e-08, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:43<00:00,  2.29it/s]\n",
      "\u001b[32m[I 2022-03-04 14:04:51,348]\u001b[0m Trial 46 finished with value: 0.018880946129057736 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0027541960452783826, 'item_alpha': 5.3109295679036066e-08, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:41<00:00,  2.42it/s]\n",
      "\u001b[32m[I 2022-03-04 14:05:45,127]\u001b[0m Trial 47 finished with value: 0.018905436725314993 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.003861969474663458, 'item_alpha': 1.4386771794822483e-10, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:29<00:00,  3.42it/s]\n",
      "\u001b[32m[I 2022-03-04 14:06:26,073]\u001b[0m Trial 48 finished with value: 0.016547542031376577 and parameters: {'train_days': 7, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 2.0637936286758094e-05, 'item_alpha': 1.5331893600909886e-10, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:31<00:00,  3.17it/s]\n",
      "\u001b[32m[I 2022-03-04 14:07:09,663]\u001b[0m Trial 49 finished with value: 0.013445913758549229 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'learning_rate': 0.00980009216059473, 'item_alpha': 1.1510690032570507e-09, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:40<00:00,  2.47it/s]\n",
      "\u001b[32m[I 2022-03-04 14:08:02,286]\u001b[0m Trial 50 finished with value: 0.018920225539412097 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0025244177472311586, 'item_alpha': 1.2691305787796563e-10, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n",
      "\u001b[32m[I 2022-03-04 14:08:57,690]\u001b[0m Trial 51 finished with value: 0.018693115846987057 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.003790944244082424, 'item_alpha': 3.9808159993728e-11, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:29<00:00,  3.37it/s]\n",
      "\u001b[32m[I 2022-03-04 14:09:39,892]\u001b[0m Trial 52 finished with value: 0.016343352989248713 and parameters: {'train_days': 7, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0024991845430594028, 'item_alpha': 2.4285331824376036e-10, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:41<00:00,  2.40it/s]\n",
      "\u001b[32m[I 2022-03-04 14:10:33,252]\u001b[0m Trial 53 finished with value: 0.018883583786764486 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.004896549477994975, 'item_alpha': 3.540791502711732e-11, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:28<00:00,  3.50it/s]\n",
      "\u001b[32m[I 2022-03-04 14:11:14,010]\u001b[0m Trial 54 finished with value: 0.016639342846667595 and parameters: {'train_days': 7, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.005214752244632936, 'item_alpha': 3.193255879489075e-11, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [02:16<00:00,  1.36s/it]\n",
      "\u001b[32m[I 2022-03-04 14:13:43,262]\u001b[0m Trial 55 finished with value: 0.015808688564610138 and parameters: {'train_days': 63, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0033793452580855735, 'item_alpha': 4.445336557557721e-12, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:17<00:00,  5.69it/s]\n",
      "\u001b[32m[I 2022-03-04 14:14:08,803]\u001b[0m Trial 56 finished with value: 0.009416219007357413 and parameters: {'train_days': 14, 'no_components': 16, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0065896304251807, 'item_alpha': 5.136518700081537e-11, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [02:11<00:00,  1.31s/it]\n",
      "\u001b[32m[I 2022-03-04 14:16:32,283]\u001b[0m Trial 57 finished with value: 0.01663477102018312 and parameters: {'train_days': 56, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0010815011572749861, 'item_alpha': 3.9632951898768473e-10, 'max_sampled': 20}. Best is trial 44 with value: 0.01908571926534241.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:44<00:00,  2.27it/s]\n",
      "\u001b[32m[I 2022-03-04 14:17:28,662]\u001b[0m Trial 58 finished with value: 0.01913275044860705 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.007204252615508536, 'item_alpha': 2.1114361236144517e-09, 'max_sampled': 20}. Best is trial 58 with value: 0.01913275044860705.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:28<00:00,  3.47it/s]\n",
      "\u001b[32m[I 2022-03-04 14:18:08,848]\u001b[0m Trial 59 finished with value: 0.016289885653636302 and parameters: {'train_days': 7, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.008022727702731262, 'item_alpha': 1.4044144718268348e-09, 'max_sampled': 20}. Best is trial 58 with value: 0.01913275044860705.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:56<00:00,  1.77it/s]\n",
      "\u001b[32m[I 2022-03-04 14:19:17,200]\u001b[0m Trial 60 finished with value: 0.019148344937062477 and parameters: {'train_days': 21, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.004304314424117918, 'item_alpha': 9.04189337565528e-11, 'max_sampled': 20}. Best is trial 60 with value: 0.019148344937062477.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:42<00:00,  2.34it/s]\n",
      "\u001b[32m[I 2022-03-04 14:20:11,572]\u001b[0m Trial 61 finished with value: 0.018920886631625156 and parameters: {'train_days': 14, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.004898069881116446, 'item_alpha': 8.793074451313431e-11, 'max_sampled': 20}. Best is trial 60 with value: 0.019148344937062477.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:52<00:00,  1.89it/s]\n",
      "\u001b[32m[I 2022-03-04 14:21:16,226]\u001b[0m Trial 62 finished with value: 0.019408516412053847 and parameters: {'train_days': 21, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.0073806328268028855, 'item_alpha': 1.1202580375132153e-08, 'max_sampled': 20}. Best is trial 62 with value: 0.019408516412053847.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:54<00:00,  1.83it/s]\n",
      "\u001b[32m[I 2022-03-04 14:22:23,312]\u001b[0m Trial 63 finished with value: 0.01923008294816757 and parameters: {'train_days': 21, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.006532909473222638, 'item_alpha': 2.6114226095191404e-09, 'max_sampled': 20}. Best is trial 62 with value: 0.019408516412053847.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:56<00:00,  1.77it/s]\n",
      "\u001b[32m[I 2022-03-04 14:23:32,267]\u001b[0m Trial 64 finished with value: 0.019344021375286673 and parameters: {'train_days': 21, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.007584123086234484, 'item_alpha': 1.2186839141271513e-08, 'max_sampled': 20}. Best is trial 62 with value: 0.019408516412053847.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:35<00:00,  2.86it/s]\n",
      "\u001b[32m[I 2022-03-04 14:24:15,908]\u001b[0m Trial 65 finished with value: 0.012869791373087655 and parameters: {'train_days': 28, 'no_components': 32, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.006888698881917499, 'item_alpha': 1.1925936497959961e-08, 'max_sampled': 20}. Best is trial 62 with value: 0.019408516412053847.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:49<00:00,  2.00it/s]\n",
      "\u001b[32m[I 2022-03-04 14:25:17,620]\u001b[0m Trial 66 finished with value: 0.01895149437687738 and parameters: {'train_days': 21, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.007435752801614483, 'item_alpha': 5.4198513681307995e-09, 'max_sampled': 20}. Best is trial 62 with value: 0.019408516412053847.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:04<00:00,  1.56it/s]\n",
      "\u001b[32m[I 2022-03-04 14:26:33,678]\u001b[0m Trial 67 finished with value: 0.018566002600241528 and parameters: {'train_days': 28, 'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.009462604408329675, 'item_alpha': 1.0297664445094809e-07, 'max_sampled': 20}. Best is trial 62 with value: 0.019408516412053847.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:59<00:00,  1.69it/s]\n",
      "\u001b[32m[I 2022-03-04 14:27:45,150]\u001b[0m Trial 68 finished with value: 0.019378287926804242 and parameters: {'train_days': 21, 'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.006116026222761785, 'item_alpha': 1.0699067754437253e-08, 'max_sampled': 20}. Best is trial 62 with value: 0.019408516412053847.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, timeout=5400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_item_alpha</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_learning_schedule</th>\n",
       "      <th>params_loss</th>\n",
       "      <th>params_max_sampled</th>\n",
       "      <th>params_no_components</th>\n",
       "      <th>params_train_days</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>0.019409</td>\n",
       "      <td>2022-03-04 14:20:11.572978</td>\n",
       "      <td>2022-03-04 14:21:16.226517</td>\n",
       "      <td>0 days 00:01:04.653539</td>\n",
       "      <td>1.120258e-08</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>21</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>0.019378</td>\n",
       "      <td>2022-03-04 14:26:33.679565</td>\n",
       "      <td>2022-03-04 14:27:45.150316</td>\n",
       "      <td>0 days 00:01:11.470751</td>\n",
       "      <td>1.069907e-08</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>21</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>0.019344</td>\n",
       "      <td>2022-03-04 14:22:23.313030</td>\n",
       "      <td>2022-03-04 14:23:32.267469</td>\n",
       "      <td>0 days 00:01:08.954439</td>\n",
       "      <td>1.218684e-08</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>21</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>0.019230</td>\n",
       "      <td>2022-03-04 14:21:16.227561</td>\n",
       "      <td>2022-03-04 14:22:23.311838</td>\n",
       "      <td>0 days 00:01:07.084277</td>\n",
       "      <td>2.611423e-09</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>21</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0.019148</td>\n",
       "      <td>2022-03-04 14:18:08.849319</td>\n",
       "      <td>2022-03-04 14:19:17.199893</td>\n",
       "      <td>0 days 00:01:08.350574</td>\n",
       "      <td>9.041893e-11</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>21</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>2022-03-04 14:16:32.284142</td>\n",
       "      <td>2022-03-04 14:17:28.662687</td>\n",
       "      <td>0 days 00:00:56.378545</td>\n",
       "      <td>2.111436e-09</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.019086</td>\n",
       "      <td>2022-03-04 14:02:19.350715</td>\n",
       "      <td>2022-03-04 14:03:14.262960</td>\n",
       "      <td>0 days 00:00:54.912245</td>\n",
       "      <td>2.333734e-08</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.018963</td>\n",
       "      <td>2022-03-04 14:01:25.625021</td>\n",
       "      <td>2022-03-04 14:02:19.349144</td>\n",
       "      <td>0 days 00:00:53.724123</td>\n",
       "      <td>2.314335e-08</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>2022-03-04 14:24:15.909622</td>\n",
       "      <td>2022-03-04 14:25:17.620215</td>\n",
       "      <td>0 days 00:01:01.710593</td>\n",
       "      <td>5.419851e-09</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>112</td>\n",
       "      <td>21</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>2022-03-04 14:19:17.201000</td>\n",
       "      <td>2022-03-04 14:20:11.571831</td>\n",
       "      <td>0 days 00:00:54.370831</td>\n",
       "      <td>8.793074e-11</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>2022-03-04 14:07:09.664260</td>\n",
       "      <td>2022-03-04 14:08:02.286517</td>\n",
       "      <td>0 days 00:00:52.622257</td>\n",
       "      <td>1.269131e-10</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.018905</td>\n",
       "      <td>2022-03-04 14:04:51.349903</td>\n",
       "      <td>2022-03-04 14:05:45.127427</td>\n",
       "      <td>0 days 00:00:53.777524</td>\n",
       "      <td>1.438677e-10</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>0.018884</td>\n",
       "      <td>2022-03-04 14:09:39.893223</td>\n",
       "      <td>2022-03-04 14:10:33.251838</td>\n",
       "      <td>0 days 00:00:53.358615</td>\n",
       "      <td>3.540792e-11</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.018881</td>\n",
       "      <td>2022-03-04 14:03:55.959950</td>\n",
       "      <td>2022-03-04 14:04:51.348688</td>\n",
       "      <td>0 days 00:00:55.388738</td>\n",
       "      <td>5.310930e-08</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>2022-03-04 13:59:54.866673</td>\n",
       "      <td>2022-03-04 14:00:47.110870</td>\n",
       "      <td>0 days 00:00:52.244197</td>\n",
       "      <td>3.054145e-08</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>112</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>2022-03-04 13:02:13.321963</td>\n",
       "      <td>2022-03-04 13:04:09.184008</td>\n",
       "      <td>0 days 00:01:55.862045</td>\n",
       "      <td>1.628248e-05</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>warp</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>28</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0.018693</td>\n",
       "      <td>2022-03-04 14:08:02.287784</td>\n",
       "      <td>2022-03-04 14:08:57.690470</td>\n",
       "      <td>0 days 00:00:55.402686</td>\n",
       "      <td>3.980816e-11</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.018577</td>\n",
       "      <td>2022-03-04 13:58:22.949993</td>\n",
       "      <td>2022-03-04 13:59:12.777043</td>\n",
       "      <td>0 days 00:00:49.827050</td>\n",
       "      <td>4.525119e-08</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>112</td>\n",
       "      <td>14</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0.018566</td>\n",
       "      <td>2022-03-04 14:25:17.621296</td>\n",
       "      <td>2022-03-04 14:26:33.678345</td>\n",
       "      <td>0 days 00:01:16.057049</td>\n",
       "      <td>1.029766e-07</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>112</td>\n",
       "      <td>28</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.017463</td>\n",
       "      <td>2022-03-04 13:19:31.387002</td>\n",
       "      <td>2022-03-04 13:20:53.746045</td>\n",
       "      <td>0 days 00:01:22.359043</td>\n",
       "      <td>8.685272e-06</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>adadelta</td>\n",
       "      <td>warp</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>21</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "62      62  0.019409 2022-03-04 14:20:11.572978 2022-03-04 14:21:16.226517   \n",
       "68      68  0.019378 2022-03-04 14:26:33.679565 2022-03-04 14:27:45.150316   \n",
       "64      64  0.019344 2022-03-04 14:22:23.313030 2022-03-04 14:23:32.267469   \n",
       "63      63  0.019230 2022-03-04 14:21:16.227561 2022-03-04 14:22:23.311838   \n",
       "60      60  0.019148 2022-03-04 14:18:08.849319 2022-03-04 14:19:17.199893   \n",
       "58      58  0.019133 2022-03-04 14:16:32.284142 2022-03-04 14:17:28.662687   \n",
       "44      44  0.019086 2022-03-04 14:02:19.350715 2022-03-04 14:03:14.262960   \n",
       "43      43  0.018963 2022-03-04 14:01:25.625021 2022-03-04 14:02:19.349144   \n",
       "66      66  0.018951 2022-03-04 14:24:15.909622 2022-03-04 14:25:17.620215   \n",
       "61      61  0.018921 2022-03-04 14:19:17.201000 2022-03-04 14:20:11.571831   \n",
       "50      50  0.018920 2022-03-04 14:07:09.664260 2022-03-04 14:08:02.286517   \n",
       "47      47  0.018905 2022-03-04 14:04:51.349903 2022-03-04 14:05:45.127427   \n",
       "53      53  0.018884 2022-03-04 14:09:39.893223 2022-03-04 14:10:33.251838   \n",
       "46      46  0.018881 2022-03-04 14:03:55.959950 2022-03-04 14:04:51.348688   \n",
       "41      41  0.018819 2022-03-04 13:59:54.866673 2022-03-04 14:00:47.110870   \n",
       "3        3  0.018800 2022-03-04 13:02:13.321963 2022-03-04 13:04:09.184008   \n",
       "51      51  0.018693 2022-03-04 14:08:02.287784 2022-03-04 14:08:57.690470   \n",
       "39      39  0.018577 2022-03-04 13:58:22.949993 2022-03-04 13:59:12.777043   \n",
       "67      67  0.018566 2022-03-04 14:25:17.621296 2022-03-04 14:26:33.678345   \n",
       "15      15  0.017463 2022-03-04 13:19:31.387002 2022-03-04 13:20:53.746045   \n",
       "\n",
       "                 duration  params_item_alpha  params_learning_rate  \\\n",
       "62 0 days 00:01:04.653539       1.120258e-08              0.007381   \n",
       "68 0 days 00:01:11.470751       1.069907e-08              0.006116   \n",
       "64 0 days 00:01:08.954439       1.218684e-08              0.007584   \n",
       "63 0 days 00:01:07.084277       2.611423e-09              0.006533   \n",
       "60 0 days 00:01:08.350574       9.041893e-11              0.004304   \n",
       "58 0 days 00:00:56.378545       2.111436e-09              0.007204   \n",
       "44 0 days 00:00:54.912245       2.333734e-08              0.002668   \n",
       "43 0 days 00:00:53.724123       2.314335e-08              0.002332   \n",
       "66 0 days 00:01:01.710593       5.419851e-09              0.007436   \n",
       "61 0 days 00:00:54.370831       8.793074e-11              0.004898   \n",
       "50 0 days 00:00:52.622257       1.269131e-10              0.002524   \n",
       "47 0 days 00:00:53.777524       1.438677e-10              0.003862   \n",
       "53 0 days 00:00:53.358615       3.540792e-11              0.004897   \n",
       "46 0 days 00:00:55.388738       5.310930e-08              0.002754   \n",
       "41 0 days 00:00:52.244197       3.054145e-08              0.002416   \n",
       "3  0 days 00:01:55.862045       1.628248e-05              0.001000   \n",
       "51 0 days 00:00:55.402686       3.980816e-11              0.003791   \n",
       "39 0 days 00:00:49.827050       4.525119e-08              0.002883   \n",
       "67 0 days 00:01:16.057049       1.029766e-07              0.009463   \n",
       "15 0 days 00:01:22.359043       8.685272e-06              0.001446   \n",
       "\n",
       "   params_learning_schedule params_loss  params_max_sampled  \\\n",
       "62                 adadelta         bpr                  20   \n",
       "68                 adadelta         bpr                  20   \n",
       "64                 adadelta         bpr                  20   \n",
       "63                 adadelta         bpr                  20   \n",
       "60                 adadelta         bpr                  20   \n",
       "58                 adadelta         bpr                  20   \n",
       "44                 adadelta         bpr                  20   \n",
       "43                 adadelta         bpr                  20   \n",
       "66                 adadelta         bpr                  20   \n",
       "61                 adadelta         bpr                  20   \n",
       "50                 adadelta         bpr                  20   \n",
       "47                 adadelta         bpr                  20   \n",
       "53                 adadelta         bpr                  20   \n",
       "46                 adadelta         bpr                  20   \n",
       "41                 adadelta         bpr                  20   \n",
       "3                  adadelta        warp                  20   \n",
       "51                 adadelta         bpr                  20   \n",
       "39                 adadelta         bpr                  20   \n",
       "67                 adadelta         bpr                  20   \n",
       "15                 adadelta        warp                  20   \n",
       "\n",
       "    params_no_components  params_train_days     state  \n",
       "62                   128                 21  COMPLETE  \n",
       "68                   128                 21  COMPLETE  \n",
       "64                   128                 21  COMPLETE  \n",
       "63                   128                 21  COMPLETE  \n",
       "60                   128                 21  COMPLETE  \n",
       "58                   128                 14  COMPLETE  \n",
       "44                   128                 14  COMPLETE  \n",
       "43                   128                 14  COMPLETE  \n",
       "66                   112                 21  COMPLETE  \n",
       "61                   128                 14  COMPLETE  \n",
       "50                   128                 14  COMPLETE  \n",
       "47                   128                 14  COMPLETE  \n",
       "53                   128                 14  COMPLETE  \n",
       "46                   128                 14  COMPLETE  \n",
       "41                   112                 14  COMPLETE  \n",
       "3                    128                 28  COMPLETE  \n",
       "51                   128                 14  COMPLETE  \n",
       "39                   112                 14  COMPLETE  \n",
       "67                   112                 28  COMPLETE  \n",
       "15                    80                 21  COMPLETE  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe().sort_values(by='value', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-04 14:37:23,991]\u001b[0m A new study created in memory with name: no-name-38fa6f34-22af-4439-b1e7-b24ee8b84852\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [03:23<00:00,  2.04s/it]\n",
      "\u001b[32m[I 2022-03-04 14:41:22,357]\u001b[0m Trial 0 finished with value: 0.020292594405080116 and parameters: {'no_components': 640, 'learning_rate': 0.002307423800929569, 'item_alpha': 1.0473012470885833e-08, 'user_alpha': 2.2692613031009611e-07, 'max_sampled': 40}. Best is trial 0 with value: 0.020292594405080116.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [03:14<00:00,  1.95s/it]\n",
      "\u001b[32m[I 2022-03-04 14:45:11,927]\u001b[0m Trial 1 finished with value: 0.020472369138518524 and parameters: {'no_components': 640, 'learning_rate': 0.0023573203145302295, 'item_alpha': 1.2144366292590317e-10, 'user_alpha': 1.6480193837622618e-07, 'max_sampled': 30}. Best is trial 1 with value: 0.020472369138518524.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [02:04<00:00,  1.24s/it]\n",
      "\u001b[32m[I 2022-03-04 14:47:38,554]\u001b[0m Trial 2 finished with value: 0.020647078550997067 and parameters: {'no_components': 384, 'learning_rate': 0.0010242987197926004, 'item_alpha': 1.7837841052172068e-08, 'user_alpha': 7.679867205099685e-09, 'max_sampled': 30}. Best is trial 2 with value: 0.020647078550997067.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [03:13<00:00,  1.93s/it]\n",
      "\u001b[32m[I 2022-03-04 14:51:26,844]\u001b[0m Trial 3 finished with value: 0.02044547573248312 and parameters: {'no_components': 640, 'learning_rate': 0.0063755029461156545, 'item_alpha': 5.221503906875142e-10, 'user_alpha': 9.87207052745664e-12, 'max_sampled': 40}. Best is trial 2 with value: 0.020647078550997067.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:27<00:00,  1.15it/s]\n",
      "\u001b[32m[I 2022-03-04 14:53:11,115]\u001b[0m Trial 4 finished with value: 0.020293309531636775 and parameters: {'no_components': 256, 'learning_rate': 0.0018307569726510175, 'item_alpha': 7.306685720862744e-10, 'user_alpha': 4.389592647883456e-09, 'max_sampled': 40}. Best is trial 2 with value: 0.020647078550997067.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [04:52<00:00,  2.93s/it]\n",
      "\u001b[32m[I 2022-03-04 14:58:53,217]\u001b[0m Trial 5 finished with value: 0.02093864302601264 and parameters: {'no_components': 1024, 'learning_rate': 0.005515584345642018, 'item_alpha': 4.3372204565061064e-08, 'user_alpha': 1.0237097081649258e-10, 'max_sampled': 30}. Best is trial 5 with value: 0.02093864302601264.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [01:18<00:00,  1.27it/s]\n",
      "\u001b[32m[I 2022-03-04 15:00:28,515]\u001b[0m Trial 6 finished with value: 0.018562397572939357 and parameters: {'no_components': 256, 'learning_rate': 0.0010158505292533157, 'item_alpha': 8.388026117811802e-07, 'user_alpha': 2.668508415794452e-07, 'max_sampled': 40}. Best is trial 5 with value: 0.02093864302601264.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [00:52<00:00,  1.91it/s]\n",
      "\u001b[32m[I 2022-03-04 15:01:32,333]\u001b[0m Trial 7 finished with value: 0.019228589905163445 and parameters: {'no_components': 128, 'learning_rate': 0.0016897833049899578, 'item_alpha': 9.656790921592212e-10, 'user_alpha': 3.25996053184883e-12, 'max_sampled': 40}. Best is trial 5 with value: 0.02093864302601264.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [02:18<00:00,  1.39s/it]\n",
      "\u001b[32m[I 2022-03-04 15:04:19,074]\u001b[0m Trial 8 finished with value: 0.020600107342495972 and parameters: {'no_components': 512, 'learning_rate': 0.001327596951950718, 'item_alpha': 1.1226491157164106e-12, 'user_alpha': 1.2837526864498003e-10, 'max_sampled': 30}. Best is trial 5 with value: 0.02093864302601264.\u001b[0m\n",
      "Epoch: 100%|██████████| 100/100 [03:39<00:00,  2.19s/it]\n",
      "\u001b[32m[I 2022-03-04 15:08:42,390]\u001b[0m Trial 9 finished with value: 0.02081205998219297 and parameters: {'no_components': 768, 'learning_rate': 0.004588941174052199, 'item_alpha': 4.0691606494816165e-08, 'user_alpha': 5.098833341318692e-09, 'max_sampled': 30}. Best is trial 5 with value: 0.02093864302601264.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    train_days = 21\n",
    "    no_components = trial.suggest_int('no_components', 128, 1024, 128)\n",
    "    learning_schedule = 'adadelta'\n",
    "    loss = 'bpr'\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-3, 1e-2)\n",
    "    item_alpha = trial.suggest_loguniform('item_alpha', 1e-12, 1e-6)\n",
    "    user_alpha = trial.suggest_loguniform('user_alpha', 1e-12, 1e-6)\n",
    "    max_sampled = trial.suggest_int('max_sampled', 20, 40, 10)\n",
    "    epochs = 100\n",
    "\n",
    "    lightfm_params = {\n",
    "        'no_components': no_components,\n",
    "        'learning_schedule': learning_schedule,\n",
    "        'loss': loss,\n",
    "        'learning_rate': learning_rate,\n",
    "        'item_alpha': item_alpha,\n",
    "        'user_alpha': user_alpha,\n",
    "        'max_sampled': max_sampled,\n",
    "    }\n",
    "\n",
    "    valid_start_date = datetime.date(2020, 9, 16)\n",
    "    valid_end_date = datetime.date(2020, 9, 22)\n",
    "    train_end_date = valid_start_date - datetime.timedelta(days=1)\n",
    "    train_start_date = valid_start_date - datetime.timedelta(days=train_days)\n",
    "\n",
    "    transactions_train = transactions.query(\"@train_start_date <= t_dat <= @train_end_date\")\n",
    "    transactions_valid = transactions.query(\"@valid_start_date <= t_dat <= @valid_end_date\")\n",
    "\n",
    "    val = transactions_valid.groupby('customer_id_idx')['article_id_idx'].apply(list).reset_index()\n",
    "\n",
    "    train = lil_matrix((n_user, n_item))\n",
    "    train[transactions_train.customer_id_idx, transactions_train.article_id_idx] = 1\n",
    "\n",
    "    model = LightFM(**lightfm_params)\n",
    "    model.fit(train, epochs=epochs, num_threads=psutil.cpu_count(logical=False), verbose=True)\n",
    "\n",
    "    index = faiss.index_factory(no_components, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "    index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, index)\n",
    "    index.add(model.item_embeddings)\n",
    "    _, idxs = index.search(model.user_embeddings, TOPK)\n",
    "\n",
    "    return mapk(val.article_id_idx, idxs[val.customer_id_idx])\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, timeout=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_item_alpha</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_sampled</th>\n",
       "      <th>params_no_components</th>\n",
       "      <th>params_user_alpha</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.020939</td>\n",
       "      <td>2022-03-04 14:53:11.115947</td>\n",
       "      <td>2022-03-04 14:58:53.216752</td>\n",
       "      <td>0 days 00:05:42.100805</td>\n",
       "      <td>4.337220e-08</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>30</td>\n",
       "      <td>1024</td>\n",
       "      <td>1.023710e-10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.020812</td>\n",
       "      <td>2022-03-04 15:04:19.075657</td>\n",
       "      <td>2022-03-04 15:08:42.389754</td>\n",
       "      <td>0 days 00:04:23.314097</td>\n",
       "      <td>4.069161e-08</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>30</td>\n",
       "      <td>768</td>\n",
       "      <td>5.098833e-09</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020647</td>\n",
       "      <td>2022-03-04 14:45:11.928808</td>\n",
       "      <td>2022-03-04 14:47:38.554058</td>\n",
       "      <td>0 days 00:02:26.625250</td>\n",
       "      <td>1.783784e-08</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>30</td>\n",
       "      <td>384</td>\n",
       "      <td>7.679867e-09</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>2022-03-04 15:01:32.334437</td>\n",
       "      <td>2022-03-04 15:04:19.074501</td>\n",
       "      <td>0 days 00:02:46.740064</td>\n",
       "      <td>1.122649e-12</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>30</td>\n",
       "      <td>512</td>\n",
       "      <td>1.283753e-10</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020472</td>\n",
       "      <td>2022-03-04 14:41:22.358368</td>\n",
       "      <td>2022-03-04 14:45:11.927540</td>\n",
       "      <td>0 days 00:03:49.569172</td>\n",
       "      <td>1.214437e-10</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>30</td>\n",
       "      <td>640</td>\n",
       "      <td>1.648019e-07</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.020445</td>\n",
       "      <td>2022-03-04 14:47:38.555243</td>\n",
       "      <td>2022-03-04 14:51:26.843832</td>\n",
       "      <td>0 days 00:03:48.288589</td>\n",
       "      <td>5.221504e-10</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>40</td>\n",
       "      <td>640</td>\n",
       "      <td>9.872071e-12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>2022-03-04 14:51:26.844993</td>\n",
       "      <td>2022-03-04 14:53:11.114830</td>\n",
       "      <td>0 days 00:01:44.269837</td>\n",
       "      <td>7.306686e-10</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>4.389593e-09</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>2022-03-04 14:37:23.993131</td>\n",
       "      <td>2022-03-04 14:41:22.357158</td>\n",
       "      <td>0 days 00:03:58.364027</td>\n",
       "      <td>1.047301e-08</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>40</td>\n",
       "      <td>640</td>\n",
       "      <td>2.269261e-07</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.019229</td>\n",
       "      <td>2022-03-04 15:00:28.516188</td>\n",
       "      <td>2022-03-04 15:01:32.333259</td>\n",
       "      <td>0 days 00:01:03.817071</td>\n",
       "      <td>9.656791e-10</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>40</td>\n",
       "      <td>128</td>\n",
       "      <td>3.259961e-12</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>2022-03-04 14:58:53.217898</td>\n",
       "      <td>2022-03-04 15:00:28.515223</td>\n",
       "      <td>0 days 00:01:35.297325</td>\n",
       "      <td>8.388026e-07</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>2.668508e-07</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number     value             datetime_start          datetime_complete  \\\n",
       "5       5  0.020939 2022-03-04 14:53:11.115947 2022-03-04 14:58:53.216752   \n",
       "9       9  0.020812 2022-03-04 15:04:19.075657 2022-03-04 15:08:42.389754   \n",
       "2       2  0.020647 2022-03-04 14:45:11.928808 2022-03-04 14:47:38.554058   \n",
       "8       8  0.020600 2022-03-04 15:01:32.334437 2022-03-04 15:04:19.074501   \n",
       "1       1  0.020472 2022-03-04 14:41:22.358368 2022-03-04 14:45:11.927540   \n",
       "3       3  0.020445 2022-03-04 14:47:38.555243 2022-03-04 14:51:26.843832   \n",
       "4       4  0.020293 2022-03-04 14:51:26.844993 2022-03-04 14:53:11.114830   \n",
       "0       0  0.020293 2022-03-04 14:37:23.993131 2022-03-04 14:41:22.357158   \n",
       "7       7  0.019229 2022-03-04 15:00:28.516188 2022-03-04 15:01:32.333259   \n",
       "6       6  0.018562 2022-03-04 14:58:53.217898 2022-03-04 15:00:28.515223   \n",
       "\n",
       "                duration  params_item_alpha  params_learning_rate  \\\n",
       "5 0 days 00:05:42.100805       4.337220e-08              0.005516   \n",
       "9 0 days 00:04:23.314097       4.069161e-08              0.004589   \n",
       "2 0 days 00:02:26.625250       1.783784e-08              0.001024   \n",
       "8 0 days 00:02:46.740064       1.122649e-12              0.001328   \n",
       "1 0 days 00:03:49.569172       1.214437e-10              0.002357   \n",
       "3 0 days 00:03:48.288589       5.221504e-10              0.006376   \n",
       "4 0 days 00:01:44.269837       7.306686e-10              0.001831   \n",
       "0 0 days 00:03:58.364027       1.047301e-08              0.002307   \n",
       "7 0 days 00:01:03.817071       9.656791e-10              0.001690   \n",
       "6 0 days 00:01:35.297325       8.388026e-07              0.001016   \n",
       "\n",
       "   params_max_sampled  params_no_components  params_user_alpha     state  \n",
       "5                  30                  1024       1.023710e-10  COMPLETE  \n",
       "9                  30                   768       5.098833e-09  COMPLETE  \n",
       "2                  30                   384       7.679867e-09  COMPLETE  \n",
       "8                  30                   512       1.283753e-10  COMPLETE  \n",
       "1                  30                   640       1.648019e-07  COMPLETE  \n",
       "3                  40                   640       9.872071e-12  COMPLETE  \n",
       "4                  40                   256       4.389593e-09  COMPLETE  \n",
       "0                  40                   640       2.269261e-07  COMPLETE  \n",
       "7                  40                   128       3.259961e-12  COMPLETE  \n",
       "6                  40                   256       2.668508e-07  COMPLETE  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe().sort_values(by='value', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "暫定良さそうパラメーター\n",
    "* no_components: 1024 (結構多くても良い)\n",
    "* learning_rate: 0.005 (epoch: 100の時)\n",
    "* user_alpha: 10^-10 (0と変わらないかも)\n",
    "* item_alpha: 10^-8 (0と変わらないかも)\n",
    "* max_sampled: 30 (40のほうが良い可能性はまだあるが、サチっていそう)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c89b5301ada1d96cd3523f144e4a3cd3ad36f6698a61e6b8277fb627756a86c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('3.9.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
